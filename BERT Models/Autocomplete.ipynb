{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporate-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np \n",
    "import re\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "human-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'that',\n",
       " 'a',\n",
       " 'single',\n",
       " 'man',\n",
       " 'in',\n",
       " 'possession',\n",
       " 'of',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'must',\n",
       " 'be',\n",
       " 'in',\n",
       " 'want',\n",
       " 'of',\n",
       " 'a',\n",
       " 'wife']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (\"pandp.txt\", \"r\") as myfile:\n",
    "  data=myfile.read().replace(\"\\n\", \" \")\n",
    "data = (data).split(\". \")\n",
    "input_seq = []\n",
    "for i in range(len(data)):\n",
    "    sent = re.sub(r'[^\\w\\s]', '', data[i]) \n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    input_seq.append(sent)\n",
    "(input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subsequent-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in input_seq:\n",
    "\tfor i in range(1, len(sentence)):\n",
    "\t\tn_gram_sequence = sentence[:i+1]\n",
    "\t\tsentences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "derived-bryan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "for sentence in (sentences):\n",
    "  for word in sentence:\n",
    "     word = re.sub(r'[^\\w\\s]', '', word) \n",
    "     word = word.lower()\n",
    "     all_words.append(word)\n",
    "\n",
    "all_words = list(set(all_words))\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_dict(all_words):\n",
    "    word_dict = {}\n",
    "    for idx, words in enumerate(all_words):\n",
    "        word_dict[words] = idx+1\n",
    "    return word_dict\n",
    "\n",
    "max_sequence_len = max([len(x) for x in sentences])\n",
    "def bag_of_word(tokenize_sen,wordict):\n",
    "    bg_token = np.zeros((max_sequence_len))\n",
    "    for idx,token in enumerate(tokenize_sen):\n",
    "        if token in wordict.keys():\n",
    "            bg_token[max_sequence_len - len(tokenize_sen)+idx] = wordict[token]   #prepadding\n",
    "        else:\n",
    "            bg_token[idx]= -1.0     # assign -1 to words not present in allwords\n",
    "    return bg_token\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = word_dict(all_words=all_words)\n",
    "tokenized = []\n",
    "for sentence in sentences:\n",
    "  tokenized.append(bag_of_word(sentence, word_index))\n",
    "\n",
    "# #Now sentences are prepadded and tokenized\n",
    "tokenized_sen_num = np.array(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optimum-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = tokenized_sen_num[:,:-1],tokenized_sen_num[:,-1]\n",
    "(tokenized_sen_num).shape\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=len(all_words)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-contributor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "3636/3636 [==============================] - 84s 22ms/step - loss: 6.4857 - accuracy: 0.0528\n",
      "Epoch 2/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 5.5244 - accuracy: 0.1178\n",
      "Epoch 3/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 5.1353 - accuracy: 0.1455\n",
      "Epoch 4/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 4.8686 - accuracy: 0.1631\n",
      "Epoch 5/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 4.6861 - accuracy: 0.1742\n",
      "Epoch 6/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 4.4962 - accuracy: 0.1877\n",
      "Epoch 7/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 4.3455 - accuracy: 0.1968\n",
      "Epoch 8/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 4.2097 - accuracy: 0.2084\n",
      "Epoch 9/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 4.0794 - accuracy: 0.2196\n",
      "Epoch 10/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 3.9486 - accuracy: 0.2353\n",
      "Epoch 11/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 3.8158 - accuracy: 0.2491\n",
      "Epoch 12/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 3.7030 - accuracy: 0.2646\n",
      "Epoch 13/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 3.5987 - accuracy: 0.2772\n",
      "Epoch 14/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 3.4988 - accuracy: 0.2954\n",
      "Epoch 15/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 3.4114 - accuracy: 0.3049\n",
      "Epoch 16/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 3.3196 - accuracy: 0.3185\n",
      "Epoch 17/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 3.2334 - accuracy: 0.3349\n",
      "Epoch 18/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 3.1544 - accuracy: 0.3476\n",
      "Epoch 19/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 3.0777 - accuracy: 0.3599\n",
      "Epoch 20/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 3.0224 - accuracy: 0.3712\n",
      "Epoch 21/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 2.9547 - accuracy: 0.3832\n",
      "Epoch 22/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 2.8990 - accuracy: 0.3919\n",
      "Epoch 23/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 2.8383 - accuracy: 0.4012\n",
      "Epoch 24/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 2.7958 - accuracy: 0.4098\n",
      "Epoch 25/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.7397 - accuracy: 0.4206\n",
      "Epoch 26/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 2.6936 - accuracy: 0.4282\n",
      "Epoch 27/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 2.6552 - accuracy: 0.4363\n",
      "Epoch 28/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 2.6191 - accuracy: 0.4404\n",
      "Epoch 29/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.5752 - accuracy: 0.4505\n",
      "Epoch 30/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.5427 - accuracy: 0.4555\n",
      "Epoch 31/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.4920 - accuracy: 0.4649\n",
      "Epoch 32/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.4684 - accuracy: 0.4718\n",
      "Epoch 33/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.4286 - accuracy: 0.4777\n",
      "Epoch 34/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.3932 - accuracy: 0.4838\n",
      "Epoch 35/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 2.3685 - accuracy: 0.4895\n",
      "Epoch 36/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 2.3344 - accuracy: 0.4924\n",
      "Epoch 37/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 2.3136 - accuracy: 0.5013\n",
      "Epoch 38/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 2.2799 - accuracy: 0.50550s - loss: 2.2798 - accuracy: 0.50\n",
      "Epoch 39/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 2.2545 - accuracy: 0.5107\n",
      "Epoch 40/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 2.2351 - accuracy: 0.5144\n",
      "Epoch 41/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 2.2124 - accuracy: 0.5180\n",
      "Epoch 42/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.1960 - accuracy: 0.5222\n",
      "Epoch 43/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.1784 - accuracy: 0.5233\n",
      "Epoch 44/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 2.1547 - accuracy: 0.5283\n",
      "Epoch 45/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.1416 - accuracy: 0.5307\n",
      "Epoch 46/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.1103 - accuracy: 0.5362\n",
      "Epoch 47/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0800 - accuracy: 0.5438\n",
      "Epoch 48/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0838 - accuracy: 0.5416\n",
      "Epoch 49/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 2.0476 - accuracy: 0.5495\n",
      "Epoch 50/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0403 - accuracy: 0.5503\n",
      "Epoch 51/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0312 - accuracy: 0.5510\n",
      "Epoch 52/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0196 - accuracy: 0.5555\n",
      "Epoch 53/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.9957 - accuracy: 0.5606\n",
      "Epoch 54/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.9759 - accuracy: 0.5634\n",
      "Epoch 55/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.9679 - accuracy: 0.5657\n",
      "Epoch 56/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.9523 - accuracy: 0.5683\n",
      "Epoch 57/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.9403 - accuracy: 0.5702\n",
      "Epoch 58/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.9353 - accuracy: 0.5718\n",
      "Epoch 59/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.9094 - accuracy: 0.5774\n",
      "Epoch 60/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.9005 - accuracy: 0.5779\n",
      "Epoch 61/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.8938 - accuracy: 0.5807\n",
      "Epoch 62/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.8764 - accuracy: 0.5844\n",
      "Epoch 63/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.8611 - accuracy: 0.5867\n",
      "Epoch 64/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.8701 - accuracy: 0.5831\n",
      "Epoch 65/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.8456 - accuracy: 0.5889\n",
      "Epoch 66/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.8420 - accuracy: 0.5894\n",
      "Epoch 67/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.8332 - accuracy: 0.5916\n",
      "Epoch 68/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.8284 - accuracy: 0.5920\n",
      "Epoch 69/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.8010 - accuracy: 0.5983\n",
      "Epoch 70/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7999 - accuracy: 0.5972\n",
      "Epoch 71/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7951 - accuracy: 0.5997\n",
      "Epoch 72/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7838 - accuracy: 0.6002\n",
      "Epoch 73/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7827 - accuracy: 0.5980\n",
      "Epoch 74/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7736 - accuracy: 0.6030\n",
      "Epoch 75/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7511 - accuracy: 0.6056\n",
      "Epoch 76/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7554 - accuracy: 0.6027\n",
      "Epoch 77/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7439 - accuracy: 0.6080\n",
      "Epoch 78/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7348 - accuracy: 0.6093\n",
      "Epoch 79/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7213 - accuracy: 0.6122\n",
      "Epoch 80/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.7261 - accuracy: 0.6115\n",
      "Epoch 81/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7057 - accuracy: 0.6153\n",
      "Epoch 82/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7073 - accuracy: 0.6157\n",
      "Epoch 83/160\n",
      "3636/3636 [==============================] - 82s 22ms/step - loss: 1.6854 - accuracy: 0.6208\n",
      "Epoch 84/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 1.6840 - accuracy: 0.6163\n",
      "Epoch 85/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.6733 - accuracy: 0.6196\n",
      "Epoch 86/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.6673 - accuracy: 0.6214\n",
      "Epoch 87/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.6593 - accuracy: 0.6237\n",
      "Epoch 88/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 1.6659 - accuracy: 0.6217\n",
      "Epoch 89/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 1.6516 - accuracy: 0.6254\n",
      "Epoch 90/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 1.6360 - accuracy: 0.6284\n",
      "Epoch 91/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 1.6503 - accuracy: 0.6256\n",
      "Epoch 92/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 1.6240 - accuracy: 0.6309\n",
      "Epoch 93/160\n",
      "3636/3636 [==============================] - 97s 27ms/step - loss: 1.6194 - accuracy: 0.6301\n",
      "Epoch 94/160\n",
      "3636/3636 [==============================] - 101s 28ms/step - loss: 1.6139 - accuracy: 0.6303\n",
      "Epoch 95/160\n",
      "3636/3636 [==============================] - 93s 26ms/step - loss: 1.6130 - accuracy: 0.6327\n",
      "Epoch 96/160\n",
      "3636/3636 [==============================] - 94s 26ms/step - loss: 1.6024 - accuracy: 0.6346\n",
      "Epoch 97/160\n",
      "3636/3636 [==============================] - 94s 26ms/step - loss: 1.5888 - accuracy: 0.6360\n",
      "Epoch 98/160\n",
      "3636/3636 [==============================] - 87s 24ms/step - loss: 1.5854 - accuracy: 0.6376\n",
      "Epoch 99/160\n",
      "3636/3636 [==============================] - 96s 26ms/step - loss: 1.5752 - accuracy: 0.6397\n",
      "Epoch 100/160\n",
      "3636/3636 [==============================] - 102s 28ms/step - loss: 1.5821 - accuracy: 0.6382\n",
      "Epoch 101/160\n",
      "3636/3636 [==============================] - 102s 28ms/step - loss: 1.5699 - accuracy: 0.6407\n",
      "Epoch 102/160\n",
      "3636/3636 [==============================] - 101s 28ms/step - loss: 1.5638 - accuracy: 0.6424\n",
      "Epoch 103/160\n",
      "3636/3636 [==============================] - 101s 28ms/step - loss: 1.5596 - accuracy: 0.6417\n",
      "Epoch 104/160\n",
      "3636/3636 [==============================] - 103s 28ms/step - loss: 1.5545 - accuracy: 0.6416\n",
      "Epoch 105/160\n",
      "3636/3636 [==============================] - 104s 29ms/step - loss: 1.5547 - accuracy: 0.6437\n",
      "Epoch 106/160\n",
      "3636/3636 [==============================] - 99s 27ms/step - loss: 1.5480 - accuracy: 0.6447\n",
      "Epoch 107/160\n",
      "3636/3636 [==============================] - 82s 22ms/step - loss: 1.5397 - accuracy: 0.6446\n",
      "Epoch 108/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.5416 - accuracy: 0.6433\n",
      "Epoch 109/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.5210 - accuracy: 0.6467\n",
      "Epoch 110/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.5221 - accuracy: 0.6486\n",
      "Epoch 111/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.5159 - accuracy: 0.6498\n",
      "Epoch 112/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.5054 - accuracy: 0.6516\n",
      "Epoch 113/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.5063 - accuracy: 0.6511\n",
      "Epoch 114/160\n",
      "3636/3636 [==============================] - 90s 25ms/step - loss: 1.5016 - accuracy: 0.6517\n",
      "Epoch 115/160\n",
      "3636/3636 [==============================] - 89s 25ms/step - loss: 1.4843 - accuracy: 0.6554\n",
      "Epoch 116/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 1.4954 - accuracy: 0.6535\n",
      "Epoch 117/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 1.4897 - accuracy: 0.6561\n",
      "Epoch 118/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 1.4816 - accuracy: 0.6560\n",
      "Epoch 119/160\n",
      "3636/3636 [==============================] - 89s 24ms/step - loss: 1.4727 - accuracy: 0.6572\n",
      "Epoch 120/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.4827 - accuracy: 0.6559\n",
      "Epoch 121/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 1.4790 - accuracy: 0.65770s - loss: 1.4\n",
      "Epoch 122/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 1.4738 - accuracy: 0.6551\n",
      "Epoch 123/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.4560 - accuracy: 0.6622\n",
      "Epoch 124/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.4537 - accuracy: 0.6611\n",
      "Epoch 125/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 1.4433 - accuracy: 0.6624\n",
      "Epoch 126/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.4426 - accuracy: 0.6629\n",
      "Epoch 127/160\n",
      "3636/3636 [==============================] - 82s 22ms/step - loss: 1.4379 - accuracy: 0.6666\n",
      "Epoch 128/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.4435 - accuracy: 0.6628\n",
      "Epoch 129/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.4461 - accuracy: 0.6627\n",
      "Epoch 130/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.4273 - accuracy: 0.6672\n",
      "Epoch 131/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4358 - accuracy: 0.6646\n",
      "Epoch 132/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 1.4228 - accuracy: 0.6681\n",
      "Epoch 133/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.4054 - accuracy: 0.6695\n",
      "Epoch 134/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 1.4113 - accuracy: 0.6684\n",
      "Epoch 135/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.4083 - accuracy: 0.6722\n",
      "Epoch 136/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 1.4121 - accuracy: 0.6678\n",
      "Epoch 137/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.3940 - accuracy: 0.6721\n",
      "Epoch 138/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.3847 - accuracy: 0.6740\n",
      "Epoch 139/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.3886 - accuracy: 0.6752\n",
      "Epoch 140/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.3822 - accuracy: 0.6752\n",
      "Epoch 141/160\n",
      "3636/3636 [==============================] - 75s 21ms/step - loss: 1.3922 - accuracy: 0.6720\n",
      "Epoch 142/160\n",
      "3636/3636 [==============================] - 76s 21ms/step - loss: 1.3730 - accuracy: 0.6748\n",
      "Epoch 143/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3756 - accuracy: 0.6750\n",
      "Epoch 144/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.3653 - accuracy: 0.6790\n",
      "Epoch 145/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 1.3669 - accuracy: 0.6769\n",
      "Epoch 146/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 1.3750 - accuracy: 0.6770\n",
      "Epoch 147/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.3706 - accuracy: 0.6772\n",
      "Epoch 148/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.3806 - accuracy: 0.6750\n",
      "Epoch 149/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 1.3747 - accuracy: 0.6748\n",
      "Epoch 150/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.3510 - accuracy: 0.68150s - loss: 1.3508 - accura\n",
      "Epoch 151/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 1.3581 - accuracy: 0.6799\n",
      "Epoch 152/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 1.3512 - accuracy: 0.6796\n",
      "Epoch 153/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.3503 - accuracy: 0.6804\n",
      "Epoch 154/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.3519 - accuracy: 0.6805\n",
      "Epoch 155/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.3331 - accuracy: 0.6846\n",
      "Epoch 156/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.3422 - accuracy: 0.6819\n",
      "Epoch 157/160\n",
      "3636/3636 [==============================] - 95s 26ms/step - loss: 1.3338 - accuracy: 0.6836\n",
      "Epoch 158/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 1.3452 - accuracy: 0.6818\n",
      "Epoch 159/160\n",
      "3636/3636 [==============================] - 87s 24ms/step - loss: 1.3457 - accuracy: 0.6815\n",
      "Epoch 160/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 1.3175 - accuracy: 0.6878\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(len(all_words)+1, 128, input_length=max_sequence_len-1))\n",
    "  model.add(Bidirectional(LSTM(64)))\n",
    "  model.add(Dense(len(all_words)+1, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  history = model.fit(xs, ys, epochs=160, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automated-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: predict-next/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: predict-next/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"predict-next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thirty-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "psychological-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lovely-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 165) for input KerasTensor(type_spec=TensorSpec(shape=(None, 165), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 166).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 165) for input KerasTensor(type_spec=TensorSpec(shape=(None, 165), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 166).\n"
     ]
    }
   ],
   "source": [
    "input_text = \"how are\"\n",
    "next_words = 1\n",
    "\n",
    "input_text = str(input_text).lower()\n",
    "input_text = input_text.split()\n",
    "inp = bag_of_word(input_text, word_index)\n",
    "inp = np.reshape(inp,(1,166))\n",
    "predict = model.predict(inp, verbose=0)\n",
    "predicted = np.argmax(predict,axis=1)\n",
    "\n",
    "output_word = \"\"\n",
    "for word, idx in word_index.items():\n",
    "    if idx == predicted:\n",
    "      output_word = (word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "driving-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_word #Predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acknowledged-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"why are you like\"\n",
    "next_words = 1\n",
    "\n",
    "input_text = str(input_text).lower()\n",
    "input_text = input_text.split()\n",
    "inp = bag_of_word(input_text, word_index)\n",
    "inp = np.reshape(inp,(1,166))\n",
    "predict = model.predict(inp, verbose=0)\n",
    "predicted = np.argmax(predict,axis=1)\n",
    "\n",
    "output_word = \"\"\n",
    "for word, idx in word_index.items():\n",
    "    if idx == predicted:\n",
    "      output_word = (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "antique-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'him'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-russell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
